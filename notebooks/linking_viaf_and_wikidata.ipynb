{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90f5e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from requests.exceptions import RequestException\n",
    "\n",
    "def extract_viaf_id(jsonld_data):\n",
    "    if isinstance(jsonld_data, dict) and '@graph' in jsonld_data:\n",
    "        for item in jsonld_data['@graph']:\n",
    "            if '@type' in item and item['@type'] == \"schema:Person\":\n",
    "                return item.get('identifier', 'NA')\n",
    "    return 'NA'\n",
    "\n",
    "def extract_wkp_id(jsonld_data):\n",
    "    graph_data = jsonld_data.get('@graph', [])\n",
    "    for entry in graph_data:\n",
    "        if 'sameAs' in entry:\n",
    "            for same_as_url in entry['sameAs']:\n",
    "                if 'wikidata.org' in same_as_url:\n",
    "                    return same_as_url.split('/')[-1]\n",
    "    return 'NA'\n",
    "\n",
    "def update_person_records(parquet_file, tsv_file, output_file):\n",
    "    \"\"\"\n",
    "    Updates person records by adding VIAF and Wikidata IDs if missing, only for new rows.\n",
    "    \n",
    "    Args:\n",
    "        parquet_file (str): Path to the parquet file with new IDs.\n",
    "        tsv_file (str): Path to the authority person links file to update.\n",
    "        output_file (str): Path for saving the updated file.\n",
    "    \"\"\"\n",
    "    \n",
    "    nle_persons_df = pd.read_parquet(parquet_file)\n",
    "    person_df = pd.read_csv(tsv_file, sep='\\t', na_filter=False)\n",
    "\n",
    "    new_ids = set(nle_persons_df['id']) - set(person_df['rara_id'])\n",
    "    relevant_columns = ['id']\n",
    "    new_rows = nle_persons_df[nle_persons_df['id'].isin(new_ids)][relevant_columns].copy()\n",
    "    new_rows.rename(columns={'id': 'rara_id'}, inplace=True)\n",
    "\n",
    "    new_rows['viaf_id'] = 'NA'\n",
    "    new_rows['wkp_id'] = 'NA'\n",
    "\n",
    "    updated_person_df = pd.concat([person_df, new_rows], ignore_index=True)\n",
    "    \n",
    "    for index, row in tqdm(new_rows.iterrows(), total=len(new_rows), desc=\"Processing New Records\"):\n",
    "        id_number = row['rara_id'].lstrip('a')\n",
    "\n",
    "        try:\n",
    "            jsonld_url = f'https://viaf.org/viaf/sourceID/ERRR|{id_number}/viaf.jsonld'\n",
    "            response = requests.get(jsonld_url)\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                jsonld_data = response.json()\n",
    "                new_viaf_id = extract_viaf_id(jsonld_data)\n",
    "                new_wkp_id = extract_wkp_id(jsonld_data)\n",
    "\n",
    "                if new_viaf_id != 'NA':\n",
    "                    new_rows.at[index, 'viaf_id'] = new_viaf_id\n",
    "                if new_wkp_id != 'NA':\n",
    "                    new_rows.at[index, 'wkp_id'] = new_wkp_id\n",
    "\n",
    "            else:\n",
    "                new_rows.at[index, 'viaf_id'] = 'NA'\n",
    "                new_rows.at[index, 'wkp_id'] = 'NA'\n",
    "\n",
    "        except RequestException:\n",
    "            new_rows.at[index, 'viaf_id'] = 'NA'\n",
    "            new_rows.at[index, 'wkp_id'] = 'NA'\n",
    "\n",
    "    final_df = pd.concat([person_df, new_rows], ignore_index=True)\n",
    "    final_df.to_csv(output_file, sep='\\t', index=False)\n",
    "    print(f\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "865ea7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing New Records: 100%|██████████████████████████████████████████████████████████| 14/14 [00:10<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "update_person_records(\n",
    "    parquet_file='test_nle_person.parquet',\n",
    "    tsv_file='test_persons.tsv',\n",
    "    output_file='persons_updated.tsv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
